<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Overdispersion</title>
    <meta charset="utf-8" />
    <meta name="author" content="Chris Mainey" />
    <meta name="date" content="2023-10-09" />
    <script src="presentation_files/header-attrs/header-attrs.js"></script>
    <script src="presentation_files/kePrint/kePrint.js"></script>
    <link href="presentation_files/lightable/lightable.css" rel="stylesheet" />
    <link rel="stylesheet" href="theme.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">





class: title-slide

# Modelling count data:
## What is overdispersion, and why should you care about it?



&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;

### &lt;img src="./assets/img/crop.png" alt="Mainard icon" height="40px" /&gt;  Dr Chris Mainey
&lt;br&gt;&lt;br&gt;

&lt;svg viewBox="0 0 512 512" style="height:1em;position:relative;display:inline-block;top:.1em;fill:#005EB8;" xmlns="http://www.w3.org/2000/svg"&gt;  &lt;path d="M464 64H48C21.49 64 0 85.49 0 112v288c0 26.51 21.49 48 48 48h416c26.51 0 48-21.49 48-48V112c0-26.51-21.49-48-48-48zm0 48v40.805c-22.422 18.259-58.168 46.651-134.587 106.49-16.841 13.247-50.201 45.072-73.413 44.701-23.208.375-56.579-31.459-73.413-44.701C106.18 199.465 70.425 171.067 48 152.805V112h416zM48 400V214.398c22.914 18.251 55.409 43.862 104.938 82.646 21.857 17.205 60.134 55.186 103.062 54.955 42.717.231 80.509-37.199 103.053-54.947 49.528-38.783 82.032-64.401 104.947-82.653V400H48z"&gt;&lt;/path&gt;&lt;/svg&gt; [c.mainey1@nhs.net](mailto:c.mainey1@nhs.net)
&lt;svg viewBox="0 0 496 512" style="height:1em;position:relative;display:inline-block;top:.1em;fill:#005EB8;" xmlns="http://www.w3.org/2000/svg"&gt;  &lt;path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"&gt;&lt;/path&gt;&lt;/svg&gt; [chrismainey](https://github.com/chrismainey)
&lt;svg viewBox="0 0 448 512" style="height:1em;position:relative;display:inline-block;top:.1em;fill:#005EB8;" xmlns="http://www.w3.org/2000/svg"&gt;  &lt;path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"&gt;&lt;/path&gt;&lt;/svg&gt;  [chrismainey](https://www.linkedin.com/in/chrismainey/)
&lt;svg viewBox="0 0 512 512" style="height:1em;position:relative;display:inline-block;top:.1em;fill:#005EB8;" xmlns="http://www.w3.org/2000/svg"&gt;  &lt;path d="M294.75 188.19h-45.92V342h47.47c67.62 0 83.12-51.34 83.12-76.91 0-41.64-26.54-76.9-84.67-76.9zM256 8C119 8 8 119 8 256s111 248 248 248 248-111 248-248S393 8 256 8zm-80.79 360.76h-29.84v-207.5h29.84zm-14.92-231.14a19.57 19.57 0 1 1 19.57-19.57 19.64 19.64 0 0 1-19.57 19.57zM300 369h-81V161.26h80.6c76.73 0 110.44 54.83 110.44 103.85C410 318.39 368.38 369 300 369z"&gt;&lt;/path&gt;&lt;/svg&gt; [0000-0002-3018-6171](https://orcid.org/0000-0002-3018-6171)
&lt;svg viewBox="0 0 496 512" style="height:1em;position:relative;display:inline-block;top:.1em;fill:#005EB8;" xmlns="http://www.w3.org/2000/svg"&gt;  &lt;path d="M336.5 160C322 70.7 287.8 8 248 8s-74 62.7-88.5 152h177zM152 256c0 22.2 1.2 43.5 3.3 64h185.3c2.1-20.5 3.3-41.8 3.3-64s-1.2-43.5-3.3-64H155.3c-2.1 20.5-3.3 41.8-3.3 64zm324.7-96c-28.6-67.9-86.5-120.4-158-141.6 24.4 33.8 41.2 84.7 50 141.6h108zM177.2 18.4C105.8 39.6 47.8 92.1 19.3 160h108c8.7-56.9 25.5-107.8 49.9-141.6zM487.4 192H372.7c2.1 21 3.3 42.5 3.3 64s-1.2 43-3.3 64h114.6c5.5-20.5 8.6-41.8 8.6-64s-3.1-43.5-8.5-64zM120 256c0-21.5 1.2-43 3.3-64H8.6C3.2 212.5 0 233.8 0 256s3.2 43.5 8.6 64h114.6c-2-21-3.2-42.5-3.2-64zm39.5 96c14.5 89.3 48.7 152 88.5 152s74-62.7 88.5-152h-177zm159.3 141.6c71.4-21.2 129.4-73.7 158-141.6h-108c-8.8 56.9-25.6 107.8-50 141.6zM19.3 352c28.6 67.9 86.5 120.4 158 141.6-24.4-33.8-41.2-84.7-50-141.6h-108z"&gt;&lt;/path&gt;&lt;/svg&gt; [www.mainard.co.uk](https://www.mainard.co.uk)

.footnote[Presentation and code available: **https://github.com/chrismainey/whats_overdispersion**]

.art_cap[R generative art - inspired by Antonio S√°nchez Chinch√≥n - @aschinchon]




---

# Count data

&gt;‚ÄúCounts can be thought of as aggregated versions or summaries of more detailed data on the occurrences of some event.‚Äù 

&lt;a id='cite-rabe-hesketh_multilevel_2012'&gt;&lt;/a&gt;(&lt;a href='#bib-rabe-hesketh_multilevel_2012'&gt;Rabe-Hesketh and Skrondal, 2012&lt;/a&gt;)

__Two common sources__ &lt;a id='cite-cameron_regression_2013'&gt;&lt;/a&gt;(&lt;a href='#bib-cameron_regression_2013'&gt;Cameron and Trivedi, 2013b&lt;/a&gt;):
+  observation of point processes
+  discretization of continuous outcomes 

--

__Several properties:__

+ Natural, whole numbers (integers), sometimes referred to as ‚Äòdiscrete.‚Äô E.g. counts of 2 or 3 are possible, but 2.5 is not.

+ Range from zero to infinity, with counts less than zero impossible

+ Counts occur in a fixed time period, with a known average rate (ùúá)
  + counts that occur with a variable time period can be characterised as rates using a time denominator

+ Not normally distributed!

---
# Count data distributions: 

.pull-left[
+ Default description is the Poisson distribution &lt;a id='cite-poisson_recherches_1837'&gt;&lt;/a&gt;(&lt;a href='#bib-poisson_recherches_1837'&gt;Poisson, 1837&lt;/a&gt;; &lt;a href='#bib-cameron_regression_2013'&gt;Cameron and Trivedi, 2013b&lt;/a&gt;).
  
  + Not defined between integers
  + Counts with low average rates are skewed
  + Asymptotically normally distributed when average rate is high
  + Single parameter `\(\lambda\)` is both mean and variance
  + __No free parameter to scale with the variance.__


{{content}}


]

.pull-right[
&lt;img src="presentation_files/figure-html/poisondistributions-1.png" width="100%" /&gt;
]

--
___Result is set variance that cannot alter in relation to data___

{{content}}

--

Similar principle for binomial distribution, where variance: `\(np(1-p)\)` is fixed by mean: `\(np\)`

---

# Assumptions...

+ Even if you don't know you are doing it, using count data many cases, is simple Poisson models:
  + Characterised by it's average rate: `\(\lambda\)`
  
+ Same idea is true for proportions/ratios which are commonly truncated Poisson distributions

+ Poisson assumptions commonly violated in, real world data &lt;a id='cite-breslow_extra-poisson_1984'&gt;&lt;/a&gt;(&lt;a href='https://doi.org/10.2307/2347661'&gt;Breslow, 1984&lt;/a&gt;)

--
&lt;br&gt;&lt;br&gt;

### Leading to:

&gt; Overdispersion: where the conditional variance is greater than the conditional mean

+ More variance in the data than we expect in the Poisson distribution
+ Error estimate is too small
+ Confidence Intervals, and usual assumption of precision of estimate are too narrow/small

---
# Example: Hospital Readmissions

&lt;img src="presentation_files/figure-html/nolimits-1.png" width="100%" /&gt;
source: [NHS Digital](https://digital.nhs.uk/data-and-information/publications/statistical/compendium-emergency-readmissions/current/specifications/emergency-readmissions-within-30-days-of-discharge-from-hospital_3#top)


__Dispersion Ratio of 86.40!__
Error is actually 86 times larger than our simple models would assume.
---
class: middle
# Methods to deal with overdispersion


_well, we need to be able to test for it first..._  &lt;a id='cite-bolker_glmm_2018'&gt;&lt;/a&gt;(&lt;a href='#bib-bolker_glmm_2018'&gt;Bolker, 2018&lt;/a&gt;)

```r
# overdispersion test
od_test&lt;-function(model, ...){
  sum(residuals(model, type="pearson")^2) / df.residual(model)
}
```

---

# 1. Ignore it...

Yes...that is an option....

--

Depends on what you are trying to do:

+ Poisson or Binomial model estimates are unbiased

+ Error will be wrong, but if using for prediction, it matters less.

---

# 2. Get more information...

Major causes of overdispersion are due to Poisson/Binomial models assumptions of the variance.

If you can characterise it better, overdispersion should be lower:

___Could examine:___

+ __Outliers:__  are there data points that are incorrect, incorrectly measured, from a different distribution?

+ __Aggregation:__ aggregating loses detail, can you alter the aggregation to add more detail to a model?

+ __Missing parameters:__ Is there more data that could help explain the variation?

+ __Poorly specified model components:__ Check whether we parametrise the predictors appropriately: e.g age, age categories, spline of age

---

# 3. Characterise the variance better

Can apply computation methods to improve the accuracy, such as:

+ Bootstrapping &lt;a id='cite-efron_bootstrap_1979'&gt;&lt;/a&gt;(&lt;a href='https://doi.org/10.1214/aos/1176344552'&gt;Efron, 1979&lt;/a&gt;): taking random samples of you data and iteratively refitting, averaging across.
+ Scale the variance in a model
+ Scale the variance 'post-hoc' (after calculation) 
+ Use mixture models
+ Model known hierarchy e.g. clustering at trust level with random-intercept.



```r
library(COUNT)
library(AER)
data("medpar")
base_model &lt;- glm(los ~ hmo + died +  factor(type), data=medpar, family="poisson")
od_test(base_model)
```

```
## [1] 6.241336
```
---

# Model output:

&lt;br&gt;&lt;br&gt;

&lt;table class="table" style="margin-left: auto; margin-right: auto;"&gt;
 &lt;thead&gt;
&lt;tr&gt;
&lt;th style="empty-cells: hide;border-bottom:hidden;" colspan="4"&gt;&lt;/th&gt;
&lt;th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="2"&gt;&lt;div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; "&gt;Confidence Interval&lt;/div&gt;&lt;/th&gt;
&lt;/tr&gt;
  &lt;tr&gt;
   &lt;th style="text-align:center;font-weight: bold;"&gt; Term &lt;/th&gt;
   &lt;th style="text-align:center;font-weight: bold;"&gt; Estimate &lt;/th&gt;
   &lt;th style="text-align:center;font-weight: bold;"&gt; Standard Error &lt;/th&gt;
   &lt;th style="text-align:center;font-weight: bold;"&gt; p-value &lt;/th&gt;
   &lt;th style="text-align:center;font-weight: bold;"&gt; Lower &lt;/th&gt;
   &lt;th style="text-align:center;font-weight: bold;"&gt; Upper &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; (Intercept) &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 9.63 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.01 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 9.41 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 9.85 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; hmo &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.93 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.02 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.88 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.97 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; died &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.78 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.02 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.75 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.81 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; factor(type)2 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 1.28 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.02 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 1.23 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 1.34 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; factor(type)3 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 2.12 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.03 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 2.01 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 2.23 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;br&gt;&lt;br&gt;
### Keep an eye on those confidence intervals...

---

# 3a. Scaling the variance: 'Robust' confidence intervals
'Sandwich' estimators can be use to scale the standard error, e.g. `sandwich` package &lt;a id='cite-white_maximum_1982'&gt;&lt;/a&gt;&lt;a id='cite-huber_behavior_1967'&gt;&lt;/a&gt;(&lt;a href='#bib-white_maximum_1982'&gt;White, 1982&lt;/a&gt;; &lt;a href='#bib-huber_behavior_1967'&gt;Huber, 1967&lt;/a&gt;)  
 

```r
library("sandwich")
library("lmtest")

tidy(coeftest(base_model, vcov = sandwich), conf.int = TRUE) 
```

&lt;table class="table" style="margin-left: auto; margin-right: auto;"&gt;
 &lt;thead&gt;
&lt;tr&gt;
&lt;th style="empty-cells: hide;border-bottom:hidden;" colspan="4"&gt;&lt;/th&gt;
&lt;th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="2"&gt;&lt;div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; "&gt;Confidence Interval&lt;/div&gt;&lt;/th&gt;
&lt;/tr&gt;
  &lt;tr&gt;
   &lt;th style="text-align:center;font-weight: bold;"&gt; Term &lt;/th&gt;
   &lt;th style="text-align:center;font-weight: bold;"&gt; Estimate &lt;/th&gt;
   &lt;th style="text-align:center;font-weight: bold;"&gt; Standard Error &lt;/th&gt;
   &lt;th style="text-align:center;font-weight: bold;"&gt; p-value &lt;/th&gt;
   &lt;th style="text-align:center;font-weight: bold;"&gt; Lower &lt;/th&gt;
   &lt;th style="text-align:center;font-weight: bold;"&gt; Upper &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; (Intercept) &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 9.63 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 1.03 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 1.00 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 9.15 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 10.13 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; hmo &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.93 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 1.05 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 1.15 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.84 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 1.03 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; died &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.78 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 1.05 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 1.00 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.70 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.86 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; factor(type)2 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 1.28 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 1.05 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 1.00 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 1.16 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 1.42 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; factor(type)3 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 2.12 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 1.12 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 1.00 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 1.69 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 2.66 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

---
# 3b. Scaling the variance: Quasi-likehood 
+ More relaxed assumption allowing scaling. &lt;a id='cite-wedderburnQuasiLikelihoodFunctionsGeneralized1974'&gt;&lt;/a&gt;(&lt;a href='https://doi.org/10.2307/2334725'&gt;Wedderburn, 1974&lt;/a&gt;)  
+ Assumes variance is a multiple of mean 
+ Estimated with GEE instead of MLE, but lacks MLE for AIC or likelihood ratio tests


```r
quasi_model &lt;- glm(los ~ hmo + died +  factor(type), data=medpar, family="quasipoisson")
od_test(quasi_model)
```

```
## [1] 6.241336
```
&lt;table class="table" style="margin-left: auto; margin-right: auto;"&gt;
 &lt;thead&gt;
&lt;tr&gt;
&lt;th style="empty-cells: hide;border-bottom:hidden;" colspan="4"&gt;&lt;/th&gt;
&lt;th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="2"&gt;&lt;div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; "&gt;Confidence Interval&lt;/div&gt;&lt;/th&gt;
&lt;/tr&gt;
  &lt;tr&gt;
   &lt;th style="text-align:center;font-weight: bold;"&gt; Term &lt;/th&gt;
   &lt;th style="text-align:center;font-weight: bold;"&gt; Estimate &lt;/th&gt;
   &lt;th style="text-align:center;font-weight: bold;"&gt; Standard Error &lt;/th&gt;
   &lt;th style="text-align:center;font-weight: bold;"&gt; p-value &lt;/th&gt;
   &lt;th style="text-align:center;font-weight: bold;"&gt; Lower &lt;/th&gt;
   &lt;th style="text-align:center;font-weight: bold;"&gt; Upper &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; (Intercept) &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 9.63 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.03 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.00 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 9.08 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 10.20 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; hmo &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.93 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.06 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.21 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.82 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 1.04 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; died &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.78 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.05 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.00 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.71 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.85 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; factor(type)2 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 1.28 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.05 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.00 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 1.16 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 1.42 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; factor(type)3 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 2.12 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.07 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.00 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 1.86 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 2.40 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

---

# 3b. Mixture models

+ We can use mixed distributions that allow us to retain Poisson but add another assumption in.

+ ___Negative Binomial___ &lt;a id='cite-hilbe2011negative'&gt;&lt;/a&gt;(&lt;a href='https://books.google.co.uk/books?id=DDxEGQuqkJoC'&gt;Hilbe, 2011&lt;/a&gt;) Can be used as Poisson with additional gamma or normal distributed assumption (more on this with random effect...)


```r
library(MASS)
nb_model &lt;- glm.nb(los ~ hmo + died +  factor(type), data=medpar)
od_test(nb_model)
```

```
## [1] 1.133281
```

&lt;table class="table" style="margin-left: auto; margin-right: auto;"&gt;
 &lt;thead&gt;
&lt;tr&gt;
&lt;th style="empty-cells: hide;border-bottom:hidden;" colspan="4"&gt;&lt;/th&gt;
&lt;th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="2"&gt;&lt;div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; "&gt;Confidence Interval&lt;/div&gt;&lt;/th&gt;
&lt;/tr&gt;
  &lt;tr&gt;
   &lt;th style="text-align:center;font-weight: bold;"&gt; Term &lt;/th&gt;
   &lt;th style="text-align:center;font-weight: bold;"&gt; Estimate &lt;/th&gt;
   &lt;th style="text-align:center;font-weight: bold;"&gt; Standard Error &lt;/th&gt;
   &lt;th style="text-align:center;font-weight: bold;"&gt; p-value &lt;/th&gt;
   &lt;th style="text-align:center;font-weight: bold;"&gt; Lower &lt;/th&gt;
   &lt;th style="text-align:center;font-weight: bold;"&gt; Upper &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; (Intercept) &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 9.59 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.03 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.00 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 9.10 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 10.12 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; hmo &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.93 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.05 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.18 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.84 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 1.03 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; died &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.79 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.04 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.00 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.73 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.85 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; factor(type)2 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 1.29 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.05 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.00 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 1.17 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 1.42 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:center;"&gt; factor(type)3 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 2.09 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.08 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 0.00 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 1.81 &lt;/td&gt;
   &lt;td style="text-align:center;"&gt; 2.43 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

---

# Multi-level models
&lt;a id='cite-goldstein_multilevel_2010'&gt;&lt;/a&gt;(&lt;a href='#bib-goldstein_multilevel_2010'&gt;Goldstein, 2010&lt;/a&gt;)

+ Sometimes we can't estimate the variance because it operates on more than one level.
+ We can adapt regressions to have both 'fixed-effects' (coefficient and variance) or random-effect (variance)

--

&lt;br&gt;&lt;br&gt;
## Example unity-level clustering

+ Regression makes assumption of independence, which is violated if there is clustering
+ E.g. are all patients unrelated, or are the patients of a particular organisations related?
+ Multiple samples at the same units (repeated measurements) is a similar concept: not independent.
+ We can allow a 'random-intercept' or cluster-specific mean, as well as a global intercept.

As example, using readmissions from earlier (but not working):

```r
library(lme4)
random_int_model &lt;- glmer(Numerator ~ (1|Level) + offset(log(Denominator)), data=sub2, family="poisson")
```
---
# Random-intercept example

&lt;br&gt;&lt;br&gt;
.pull-left[
&lt;img src="presentation_files/figure-html/rintexample1-1.png" width="100%" /&gt;
]

--

.pull-right[
&lt;img src="presentation_files/figure-html/rintexample2-1.png" width="100%" /&gt;

]

---

# Random-intercept model


```r
library(sjPlot)
plot_model(random_int_model, type="re")
```

&lt;img src="presentation_files/figure-html/sjp-1.png" width="100%" /&gt;
---

# Post-hoc adjustment

+ Based on meta-analysis of trials &lt;a id='cite-dersimonian_meta-analysis_1986'&gt;&lt;/a&gt;(&lt;a href='https://doi.org/10.1016/0197-2456(86)90046-2'&gt;DerSimonian and Laird, 1986&lt;/a&gt;)
+ Spiegelhalter showed how to apply them in healthcare, including funnel plots  &lt;a id='cite-spiegelhalter_statistical_2012'&gt;&lt;/a&gt;&lt;a id='cite-spiegelhalterHandlingOverdispersionPerformance2005'&gt;&lt;/a&gt;(&lt;a href='https://doi.org/10.1111/j.1467-985x.2011.01010.x'&gt;Spiegelhalter Sherlaw-Johnson et al., 2012&lt;/a&gt;; &lt;a href='https://doi.org/10.1136/qshc.2005.013755'&gt;Spiegelhalter, 2005&lt;/a&gt;)
+ Essentially estimating the dispersion ratio and scaling based on it, the number of clusters and within-cluster variance.
+ Same assumption, and equivalent to random-intercept model

--

.pull-left[
&lt;img src="presentation_files/figure-html/funnelundjust-1.png" width="100%" /&gt;
]
.pull-right[
&lt;img src="presentation_files/figure-html/funneladjust-1.png" width="100%" /&gt;
]
---
# Common objections

--
&gt; It's quite complicated.

Yes, it can be.  Main point is that your model is likely being too optimistic about it's error and you will be falsely assured of something by using it.

--
&gt; We prefer the normal limits, as we don't want to miss anything

You can do, but your false positives are high.

--
&gt; Doesn't look like much of a funnel anymore

This is because the additive overdispersion component is very large and dominating the new control limit.  This is exactly ___why___ you need to account for it.

--
&gt; Isn't it just picking how many outliers I want?

Well...sort of... yes.  If you have outliers, you investigate them first before changing the system.  Wider philosophical problem with outlier investigation though...

--

&gt; We can't tell which OD- adjustment method to chose...

Welcome to the wonderful world of Statistics. It's all shades of grey...

---

# Conclusions

+ We model and use count data all the time in healthcare analytics: even counting binary events.

+ Default assumptions for count data relate to Poisson and Binomial distributions, but these distributions have a very fixed expectation of the variance.

--

+ Real-world data is never as perfect as these distributions assume, so you usually underestimate the variance in your model, known as ___overdispersion___

--

+ If you can:
  + Get more data and inspect for aggregation, outlier etc.
  + Add more parameters if possible

+ You can scale the variance simply with quasi-models, or simply report dispersion ratio.

+ Other adjustment are all takes on the clustering / 'within and between' variance concepts.

+ Negative binomial is a good start, use random-intercept models if appropriate.

+ Post-hoc adjustment is ok, if you can't do it in the model.

--

&gt; If you know something is wrong, do you still report it?

---
class: references
# References (1)

Bolker, B. M. (2018). _GLMM FAQ_.

Breslow, N. E. (1984). "Extra-Poisson Variation in Log-Linear Models".
In: _Journal of the Royal Statistical Society. Series C (Applied
Statistics)_ 33.1, pp. 38-44. ISSN: 00359254, 14679876. DOI:
10.2307/2347661.

Cameron, A. C. and P. K. Trivedi (2013b). _Regression Analysis of Count
Data_. Cambridge University Press. ISBN: 978-1-107-01416-9.

DerSimonian, R. and N. Laird (1986). "Meta-Analysis in Clinical
Trials". In: _Controlled Clinical Trials_ 7.3, pp. 177-88. ISSN:
0197-2456 (Print) 0197-2456. DOI: 10.1016/0197-2456(86)90046-2.

Efron, B. (1979). "Bootstrap Methods: Another Look at the Jackknife".
In: _The Annals of Statistics_ 7.1, pp. 1-26. ISSN: 0090-5364. DOI:
10.1214/aos/1176344552.

Goldstein, H. (2010). _Multilevel Statistical Models_. John Wiley &amp;
Sons Inc. ISBN: 978-0-470-97340-0.

Hilbe, J. (2011). _Negative Binomial Regression_. Cambridge University
Press. ISBN: 978-1-139-50006-7.
&lt;https://books.google.co.uk/books?id=DDxEGQuqkJoC&gt;.

Huber, P. J. (1967). "The Behavior of Maximum Likelihood Estimates
under Nonstandard Conditions". In: Proceedings of the Fifth Berkeley
Symposium on Mathematical Statistics and Probability, Volume 1:
Statistics. Fifth Berkeley Symposium on Mathematical Statistics and
Probability. University of California Press, pp. 221-233. ISBN:
0097-0433.

Poisson, S. D. (1837). _Recherches Sur La Probabilit√© Des Jugements En
Mati√®re Criminelle et En Mati√®re Civile: Pr√©c√©d√©es Des R√®gles G√©n√©rales
Du Calcul Des Probabilit√©s_. Bachelier.

---
class: references
# References (2)

Rabe-Hesketh, S. and A. Skrondal (2012). "Multilevel and Longitudinal
Modeling Using Stata, Volumes I and II, Third Edition". In: 3rd. Taylor
&amp; Francis. ISBN: 978-1-59718-108-2.

Spiegelhalter, D. J. (2005). "Handling Over-Dispersion of Performance
Indicators". In: _Quality and Safety in Health Care_ 14.5, pp. 347-351.
DOI: 10.1136/qshc.2005.013755.

Spiegelhalter, D., C. Sherlaw-Johnson, M. Bardsley, et al. (2012).
"Statistical Methods for Healthcare Regulation: Rating, Screening and
Surveillance". In: _Journal of the Royal Statistical Society: Series A
(Statistics in Society)_ 175.1, pp. 1-47. ISSN: 09641998. DOI:
10.1111/j.1467-985x.2011.01010.x.

Wedderburn, R. W. M. (1974). "Quasi-Likelihood Functions, Generalized
Linear Models, and the Gauss-Newton Method". In: _Biometrika_ 61.3, pp.
439-447. ISSN: 00063444. DOI: 10.2307/2334725.

White, H. (1982). "Maximum Likelihood Estimation of Misspecified
Models". In: _Econometrica_ 50.1, pp. 1-25.

    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"slideNumberFormat": "%current%",
"highlightStyle": "github",
"highlightLines": true,
"ratio": "16:9",
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
