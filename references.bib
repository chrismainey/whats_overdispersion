@online{bolker_glmm_2018,
  ids = {bolkerGLMMFAQ2018},
  title = {{{GLMM FAQ}}},
  author = {Bolker, Benjamin M.},
  date = {2018}
}

@article{breslow_extra-poisson_1984,
  title = {Extra-{{Poisson Variation}} in {{Log-Linear Models}}},
  author = {Breslow, N. E.},
  date = {1984},
  journaltitle = {Journal of the Royal Statistical Society. Series C (Applied Statistics)},
  volume = {33},
  number = {1},
  pages = {38--44},
  issn = {00359254, 14679876},
  doi = {10.2307/2347661},
  abstract = {A modification of the iterated reweighted least squares scheme of Williams (1982) conveniently accommodates extra-Poisson variation when fitting log-linear models to tables of frequencies or rates. The method is applied to the analysis of cancer death rates by age and birth cohort and to testing for mutagenic effects in a standard bioassay.},
  file = {C:\Users\ChrisMainey\Zotero\storage\7AST98YS\Breslow_1984_Extra-Poisson Variation in Log-Linear Models.pdf}
}

@incollection{cameron_model_2013,
  title = {Model {{Specification}} and {{Estimation}}},
  booktitle = {Regression {{Analysis}} of {{Count Data}}},
  author = {Cameron, A. C. and Trivedi, P. K.},
  editor = {Cameron, Colin A. and Trivedi, Pravin K.},
  date = {2013},
  series = {Econometric {{Society Monographs}}},
  edition = {2},
  pages = {21--68},
  publisher = {{Cambridge University Press}},
  location = {{Cambridge}},
  abstract = {INTRODUCTIONThis chapter presents the general modeling approaches most often used in count data analysis – likelihood-based, generalized linear models, and moment-based. Statistical inference for these nonlinear regression models is based on asymptotic theory, which is also summarized.The models and results vary according to the strength of the distributional assumptions made. Likelihood-based models and the associated maximum likelihood estimator require complete specification of the distribution. Statistical inference is usually performed under the assumption that the distribution is correctly specified.A less parametric analysis assumes that some aspects of the distribution of the dependent variable are correctly specified, whereas others are not specified or, if they are specified, are potentially misspecified. For count data models, considerable emphasis has been placed on analysis based on the assumption of correct specification of the conditional mean or of correct specification of both the conditional mean and the conditional variance. This is a nonlinear generalization of the linear regression model, in which consistency requires correct specification of the mean and efficient estimation requires correct specification of the mean and variance. It is a special case of the class of generalized linear models that is widely used in the statistics literature. Estimators for generalized linear models coincide with maximum likelihood estimators if the specified density is in the linear exponential family. But even then the analytical distribution of the same estimator can differ across the two approaches if different second moment assumptions are made.},
  isbn = {978-1-107-01416-9}
}

@book{cameron_regression_2013,
  title = {Regression {{Analysis}} of {{Count Data}}},
  author = {Cameron, A. C. and Trivedi, P. K.},
  date = {2013},
  publisher = {{Cambridge University Press}},
  isbn = {978-1-107-01416-9}
}

@article{dersimonian_meta-analysis_1986,
  ids = {dersimonianMetaanalysisClinicalTrials1986a,dersimonianMetaanalysisClinicalTrials1986b},
  title = {Meta-Analysis in Clinical Trials},
  author = {DerSimonian, R. and Laird, N.},
  date = {1986-09},
  journaltitle = {Controlled Clinical Trials},
  shortjournal = {Control. Clin. Trials},
  volume = {7},
  number = {3},
  pages = {177--88},
  issn = {0197-2456 (Print) 0197-2456},
  doi = {10.1016/0197-2456(86)90046-2},
  abstract = {This paper examines eight published reviews each reporting results from several related trials. Each review pools the results from the relevant trials in order to evaluate the efficacy of a certain treatment for a specified medical condition. These reviews lack consistent assessment of homogeneity of treatment effect before pooling. We discuss a random effects approach to combining evidence from a series of experiments comparing two treatments. This approach incorporates the heterogeneity of effects in the analysis of the overall treatment efficacy. The model can be extended to include relevant covariates which would reduce the heterogeneity and allow for more specific therapeutic recommendations. We suggest a simple noniterative procedure for characterizing the distribution of treatment effects in a series of studies.},
  langid = {english},
  keywords = {Clinical Trials as Topic/*methods,Humans,{Models, Theoretical},Research Design,Statistics as Topic}
}

@article{efron_bootstrap_1979,
  ids = {efronBootstrapMethodsAnother1979a},
  title = {Bootstrap {{Methods}}: {{Another Look}} at the {{Jackknife}}},
  author = {Efron, B.},
  date = {1979-01},
  journaltitle = {The Annals of Statistics},
  volume = {7},
  number = {1},
  pages = {1--26},
  issn = {0090-5364},
  doi = {10.1214/aos/1176344552},
  abstract = {We discuss the following problem: given a random sample \$\textbackslash mathbf\{X\} = (X\_1, X\_2, \textbackslash cdots, X\_n)\$ from an unknown probability distribution \$F\$, estimate the sampling distribution of some prespecified random variable \$R(\textbackslash mathbf\{X\}, F)\$, on the basis of the observed data \$\textbackslash mathbf\{x\}\$. (Standard jackknife theory gives an approximate mean and variance in the case \$R(\textbackslash mathbf\{X\}, F) = \textbackslash theta(\textbackslash hat\{F\}) - \textbackslash theta(F), \textbackslash theta\$ some parameter of interest.) A general method, called the "bootstrap," is introduced, and shown to work satisfactorily on a variety of estimation problems. The jackknife is shown to be a linear approximation method for the bootstrap. The exposition proceeds by a series of examples: variance of the sample median, error rates in a linear discriminant analysis, ratio estimation, estimating regression parameters, etc.},
  langid = {english},
  keywords = {bootstrap,discriminant analysis,error rate estimation,Jackknife,nonlinear regression,nonparametric variance estimation,resampling,subsample values},
  file = {C\:\\Users\\ChrisMainey\\Zotero\\storage\\QZJPKYPU\\Efron_1979_Bootstrap Methods.pdf;C\:\\Users\\ChrisMainey\\Zotero\\storage\\TV3UDYPT\\Efron_1979_Bootstrap Methods.pdf}
}

@book{goldstein_multilevel_2010,
  title = {Multilevel {{Statistical Models}}},
  author = {Goldstein, Harvey},
  date = {2010},
  publisher = {{John Wiley \& Sons Inc}},
  isbn = {978-0-470-97340-0},
  keywords = {Multilevel models (Statistics)}
}

@book{hilbe2011negative,
  title = {Negative Binomial Regression},
  author = {Hilbe, J.M.},
  date = {2011},
  publisher = {{Cambridge University Press}},
  url = {https://books.google.co.uk/books?id=DDxEGQuqkJoC},
  isbn = {978-1-139-50006-7}
}

@inproceedings{huber_behavior_1967,
  title = {The Behavior of Maximum Likelihood Estimates under Nonstandard Conditions},
  author = {Huber, Peter J.},
  date = {1967},
  series = {Fifth {{Berkeley Symposium}} on {{Mathematical Statistics}} and {{Probability}}},
  pages = {221--233},
  publisher = {{University of California Press}},
  eventtitle = {Proceedings of the {{Fifth Berkeley Symposium}} on {{Mathematical Statistics}} and {{Probability}}, {{Volume}} 1: {{Statistics}}},
  isbn = {0097-0433},
  file = {C:\Users\ChrisMainey\Zotero\storage\TW2FW8C4\Huber_1967_The behavior of maximum likelihood estimates under nonstandard conditions.pdf}
}

@book{poisson_recherches_1837,
  title = {Recherches Sur La Probabilité Des Jugements En Matière Criminelle et En Matière Civile: Précédées Des Règles Générales Du Calcul Des Probabilités},
  author = {Poisson, S. D.},
  date = {1837},
  publisher = {{Bachelier}}
}

@incollection{rabe-hesketh_multilevel_2012,
  title = {Multilevel and {{Longitudinal Modeling Using Stata}}, {{Volumes I}} and {{II}}, {{Third Edition}}},
  author = {Rabe-Hesketh, S. and Skrondal, A.},
  date = {2012},
  edition = {3rd},
  publisher = {{Taylor \& Francis}},
  isbn = {978-1-59718-108-2}
}

@article{sellers_flexible_2010,
  title = {A Flexible Regression Model for Count Data},
  author = {Sellers, Kimberly F. and Shmueli, Galit},
  date = {2010-06},
  journaltitle = {Ann. Appl. Stat.},
  volume = {4},
  number = {2},
  pages = {943--961},
  issn = {1932-6157},
  doi = {10.1214/09-aoas306},
  abstract = {Poisson regression is a popular tool for modeling count data and is applied in a vast array of applications from the social to the physical sciences and beyond. Real data, however, are often over- or under-dispersed and, thus, not conducive to Poisson regression. We propose a regression model based on the Conway-Maxwell-Poisson (COM-Poisson) distribution to address this problem. The COM-Poisson regression generalizes the well-known Poisson and logistic regression models, and is suitable for fitting count data with a wide range of dispersion levels. With a GLM approach that takes advantage of exponential family properties, we discuss model estimation, inference, diagnostics, and interpretation, and present a test for determining the need for a COM-Poisson regression over a standard Poisson regression. We compare the COM-Poisson to several alternatives and illustrate its advantages and usefulness using three data sets with varying dispersion.},
  langid = {english},
  keywords = {Conway-Maxwell-Poisson (COM-Poisson) distribution,dispersion,generalized linear models (GLM),generalized Poisson},
  file = {C:\Users\ChrisMainey\Zotero\storage\574TWKSI\Sellers_Shmueli_2010_A flexible regression model for count data.pdf}
}

@article{shmueli_useful_2005,
  title = {A Useful Distribution for Fitting Discrete Data: Revival of the {{Conway}}–{{Maxwell}}–{{Poisson}} Distribution},
  author = {Shmueli, Galit and Minka, Thomas P. and Kadane, Joseph B. and Borle, Sharad and Boatwright, Peter},
  date = {2005},
  journaltitle = {Journal of the Royal Statistical Society: Series C (Applied Statistics)},
  shortjournal = {J. Roy. Stat. Soc. Ser. C. (Appl. Stat.)},
  volume = {54},
  number = {1},
  pages = {127--142},
  doi = {10.1111/j.1467-9876.2005.00474.x},
  abstract = {Summary. A useful discrete distribution (the Conway–Maxwell–Poisson distribution) is revived and its statistical and probabilistic properties are introduced and explored. This distribution is a two‐parameter extension of the Poisson distribution that generalizes some well‐known discrete distributions (Poisson, Bernoulli and geometric). It also leads to the generalization of distributions derived from these discrete distributions (i.e. the binomial and negative binomial distributions). We describe three methods for estimating the parameters of the Conway–Maxwell–Poisson distribution. The first is a fast simple weighted least squares method, which leads to estimates that are sufficiently accurate for practical purposes. The second method, using maximum likelihood, can be used to refine the initial estimates. This method requires iterations and is more computationally intensive. The third estimation method is Bayesian. Using the conjugate prior, the posterior density of the parameters of the Conway–Maxwell–Poisson distribution is easily computed. It is a flexible distribution that can account for overdispersion or underdispersion that is commonly encountered in count data. We also explore two sets of real world data demonstrating the flexibility and elegance of the Conway–Maxwell–Poisson distribution in fitting count data which do not seem to follow the Poisson distribution.},
  file = {C:\Users\ChrisMainey\Zotero\storage\9IYBSZUR\Shmueli et al_2005_A useful distribution for fitting discrete data.pdf}
}

@article{spiegelhalter_statistical_2012,
  ids = {spiegelhalterStatisticalMethodsHealthcare2012a,spiegelhalterStatisticalMethodsHealthcare2012b,spiegelhalterStatisticalMethodsHealthcare2012c,spiegelhalterStatisticalMethodsHealthcare2012d,spiegelhalterStatisticalMethodsHealthcare2012e,spiegelhalterStatisticalMethodsHealthcare2012g},
  title = {Statistical Methods for Healthcare Regulation: Rating, Screening and Surveillance},
  author = {Spiegelhalter, David and Sherlaw-Johnson, Christopher and Bardsley, Martin and Blunt, Ian and Wood, Christopher and Grigg, Olivia},
  date = {2012},
  journaltitle = {Journal of the Royal Statistical Society: Series A (Statistics in Society)},
  shortjournal = {J. Roy. Stat. Soc. Ser. A. (Stat. Soc.)},
  volume = {175},
  number = {1},
  pages = {1--47},
  issn = {09641998},
  doi = {10.1111/j.1467-985x.2011.01010.x},
  abstract = {Summary. Current demand for accountability and efficiency of healthcare organizations, combined with the greater availability of routine data on clinical care and outcomes, has led to an increased focus on statistical methods in healthcare regulation. We consider three different regulatory functions in which statistical analysis plays a vital role: rating organizations, deciding whom to inspect and continuous surveillance for arising problems. A common approach to data standardization based on (possibly overdispersed) Z-scores is proposed, although specific tools are used for assessing performance against a target, combining indicators when screening for inspection, and continuous monitoring using risk-adjusted sequential testing procedures. We pay particular attention to the problem of simultaneously monitoring over 200000 indicators for excess mortality, both with respect to the statistical issues surrounding massive multiplicity, and the organizational aspects of dealing with such a complex but high profile process.},
  keywords = {Funnel plot,League table,Overdispersion,Risk-adjusted cumulative sum,Risk-based inspection,Statistical process control},
  file = {C\:\\Users\\ChrisMainey\\Zotero\\storage\\46CSHK37\\Spiegelhalter et al_2012_Statistical methods for healthcare regulation.pdf;C\:\\Users\\ChrisMainey\\Zotero\\storage\\NAVYT7PE\\Spiegelhalter et al_2012_Statistical methods for healthcare regulation.pdf;C\:\\Users\\ChrisMainey\\Zotero\\storage\\X3YTIDZR\\Spiegelhalter et al_2012_Statistical methods for healthcare regulation.pdf;C\:\\Users\\ChrisMainey\\Zotero\\storage\\YDKUNMXH\\Spiegelhalter et al_2012_Statistical methods for healthcare regulation.pdf}
}

@article{spiegelhalterHandlingOverdispersionPerformance2005,
  ids = {spiegelhalterHandlingOverdispersionPerformance2005a,spiegelhalterHandlingOverdispersionPerformance2005b},
  title = {Handling Over-Dispersion of Performance Indicators},
  author = {Spiegelhalter, D. J.},
  date = {2005},
  journaltitle = {Quality and Safety in Health Care},
  volume = {14},
  number = {5},
  pages = {347--351},
  doi = {10.1136/qshc.2005.013755},
  abstract = {Objectives: A problem can arise when a performance indicator shows substantially more variability than would be expected by chance alone, since ignoring such “over-dispersion” could lead to a large number of institutions being inappropriately classified as “abnormal”. A number of options for handling this phenomenon are investigated, ranging from improved risk stratification to fitting a statistical model that robustly estimates the degree of over-dispersion. Design: Retrospective analysis of publicly available data on survival following coronary artery bypass grafts, emergency readmission rates, and teenage pregnancies. Setting: NHS trusts in England. Results: Funnel plots clearly show the influence of the method chosen for dealing with over-dispersion on the “banding” a trust receives. Both multiplicative and additive approaches are feasible and give intuitively reasonable results, but the additive random effects formulation appears to have a stronger conceptual foundation. Conclusion: A random effects model may offer a reasonable solution. This method has now been adopted by the UK Healthcare Commission in their derivation of star ratings.},
  file = {C\:\\Users\\ChrisMainey\\Zotero\\storage\\Q2V47E77\\Spiegelhalter_2005_Handling over-dispersion of performance indicators.pdf;C\:\\Users\\ChrisMainey\\Zotero\\storage\\VQ5VXYPN\\Spiegelhalter_2005_Handling over-dispersion of performance indicators.pdf;C\:\\Users\\ChrisMainey\\Zotero\\storage\\ZLTE6FBZ\\Spiegelhalter_2005_Handling over-dispersion of performance indicators.pdf}
}

@article{wedderburnQuasiLikelihoodFunctionsGeneralized1974,
  title = {Quasi-{{Likelihood Functions}}, {{Generalized Linear Models}}, and the {{Gauss-Newton Method}}},
  author = {Wedderburn, R. W. M.},
  date = {1974},
  journaltitle = {Biometrika},
  volume = {61},
  number = {3},
  pages = {439--447},
  issn = {00063444},
  doi = {10.2307/2334725},
  abstract = {To define a likelihood we have to specify the form of distribution of the observations, but to define a quasi-likelihood function we need only specify a relation between the mean and variance of the observations and the quasi-likelihood can then be used for estimation. For a one-parameter exponential family the log likelihood is the same as the quasi-likelihood and it follows that assuming a one-parameter exponential family is the weakest sort of distributional assumption that can be made. The Gauss-Newton method for calculating nonlinear least squares estimates generalizes easily to deal with maximum quasi-likelihood estimates, and a rearrangement of this produces a generalization of the method described by Nelder \& Wedderburn (1972).},
  file = {C:\Users\ChrisMainey\Zotero\storage\RY7GRABC\Wedderburn_1974_Quasi-Likelihood Functions, Generalized Linear Models, and the Gauss-Newton.pdf}
}

@article{white_maximum_1982,
  title = {Maximum {{Likelihood Estimation}} of {{Misspecified Models}}},
  author = {White, Halbert},
  date = {1982},
  journaltitle = {Econometrica},
  shortjournal = {Econometrica},
  volume = {50},
  number = {1},
  pages = {1--25},
  keywords = {❓ Multiple DOI},
  file = {C:\Users\ChrisMainey\Zotero\storage\95RTGZI4\White_1982_Maximum Likelihood Estimation of Misspecified Models.pdf}
}
